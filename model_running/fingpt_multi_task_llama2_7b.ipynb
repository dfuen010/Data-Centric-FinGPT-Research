{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "8ed5b772",
      "metadata": {
        "id": "8ed5b772",
        "papermill": {
          "duration": 0.008257,
          "end_time": "2024-02-27T09:56:17.395428",
          "exception": false,
          "start_time": "2024-02-27T09:56:17.387171",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "## Set up"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "c9fb7907",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-02-27T09:56:17.413386Z",
          "iopub.status.busy": "2024-02-27T09:56:17.413075Z",
          "iopub.status.idle": "2024-02-27T09:57:36.318307Z",
          "shell.execute_reply": "2024-02-27T09:57:36.317108Z"
        },
        "id": "c9fb7907",
        "outputId": "01ab2166-764d-4cb6-b26e-cd35b15b2a8d",
        "papermill": {
          "duration": 78.916584,
          "end_time": "2024-02-27T09:57:36.320368",
          "exception": false,
          "start_time": "2024-02-27T09:56:17.403784",
          "status": "completed"
        },
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting transformers==4.37.0\n",
            "  Downloading transformers-4.37.0-py3-none-any.whl (8.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.4/8.4 MB\u001b[0m \u001b[31m28.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting peft==0.5.0\n",
            "  Downloading peft-0.5.0-py3-none-any.whl (85 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.6/85.6 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting datasets==2.16.1\n",
            "  Downloading datasets-2.16.1-py3-none-any.whl (507 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m507.1/507.1 kB\u001b[0m \u001b[31m26.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers==4.37.0) (3.13.4)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from transformers==4.37.0) (0.20.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.37.0) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers==4.37.0) (24.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.37.0) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.37.0) (2023.12.25)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers==4.37.0) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers==4.37.0) (0.15.2)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.37.0) (0.4.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers==4.37.0) (4.66.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from peft==0.5.0) (5.9.5)\n",
            "Requirement already satisfied: torch>=1.13.0 in /usr/local/lib/python3.10/dist-packages (from peft==0.5.0) (2.2.1+cu121)\n",
            "Collecting accelerate (from peft==0.5.0)\n",
            "  Downloading accelerate-0.29.2-py3-none-any.whl (297 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m297.4/297.4 kB\u001b[0m \u001b[31m24.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets==2.16.1) (14.0.2)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets==2.16.1) (0.6)\n",
            "Collecting dill<0.3.8,>=0.3.0 (from datasets==2.16.1)\n",
            "  Downloading dill-0.3.7-py3-none-any.whl (115 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.3/115.3 kB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets==2.16.1) (2.0.3)\n",
            "Collecting xxhash (from datasets==2.16.1)\n",
            "  Downloading xxhash-3.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting multiprocess (from datasets==2.16.1)\n",
            "  Downloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m14.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec[http]<=2023.10.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets==2.16.1) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets==2.16.1) (3.9.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==2.16.1) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==2.16.1) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==2.16.1) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==2.16.1) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==2.16.1) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==2.16.1) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers==4.37.0) (4.11.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.37.0) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.37.0) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.37.0) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.37.0) (2024.2.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft==0.5.0) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft==0.5.0) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft==0.5.0) (3.1.3)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=1.13.0->peft==0.5.0)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=1.13.0->peft==0.5.0)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=1.13.0->peft==0.5.0)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=1.13.0->peft==0.5.0)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch>=1.13.0->peft==0.5.0)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch>=1.13.0->peft==0.5.0)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch>=1.13.0->peft==0.5.0)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=1.13.0->peft==0.5.0)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=1.13.0->peft==0.5.0)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.19.3 (from torch>=1.13.0->peft==0.5.0)\n",
            "  Using cached nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch>=1.13.0->peft==0.5.0)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft==0.5.0) (2.2.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.13.0->peft==0.5.0)\n",
            "  Using cached nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "INFO: pip is looking at multiple versions of multiprocess to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting multiprocess (from datasets==2.16.1)\n",
            "  Downloading multiprocess-0.70.15-py310-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m17.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets==2.16.1) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets==2.16.1) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets==2.16.1) (2024.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets==2.16.1) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.13.0->peft==0.5.0) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.13.0->peft==0.5.0) (1.3.0)\n",
            "Installing collected packages: xxhash, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, dill, nvidia-cusparse-cu12, nvidia-cudnn-cu12, multiprocess, nvidia-cusolver-cu12, transformers, datasets, accelerate, peft\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.38.2\n",
            "    Uninstalling transformers-4.38.2:\n",
            "      Successfully uninstalled transformers-4.38.2\n",
            "Successfully installed accelerate-0.29.2 datasets-2.16.1 dill-0.3.7 multiprocess-0.70.15 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.1.105 peft-0.5.0 transformers-4.37.0 xxhash-3.4.1\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (0.1.99)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (0.29.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (24.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate) (6.0.1)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.2.1+cu121)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.20.3)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.4.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.13.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (4.11.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2023.6.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2.19.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2.2.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.10.0->accelerate) (12.4.127)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (4.66.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2024.2.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.2.1+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.13.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.11.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2023.6.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.10/dist-packages (from torch) (2.19.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.2.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch) (12.4.127)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
            "Requirement already satisfied: peft in /usr/local/lib/python3.10/dist-packages (0.5.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from peft) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from peft) (24.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from peft) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from peft) (6.0.1)\n",
            "Requirement already satisfied: torch>=1.13.0 in /usr/local/lib/python3.10/dist-packages (from peft) (2.2.1+cu121)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (from peft) (4.37.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from peft) (4.66.2)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (from peft) (0.29.2)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.10/dist-packages (from peft) (0.4.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (3.13.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (4.11.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (2023.6.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (2.19.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (12.1.105)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (2.2.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.13.0->peft) (12.4.127)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from accelerate->peft) (0.20.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers->peft) (2023.12.25)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers->peft) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers->peft) (0.15.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.13.0->peft) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers->peft) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers->peft) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers->peft) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers->peft) (2024.2.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.13.0->peft) (1.3.0)\n",
            "Collecting bitsandbytes\n",
            "  Downloading bitsandbytes-0.43.1-py3-none-manylinux_2_24_x86_64.whl (119.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m119.8/119.8 MB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from bitsandbytes) (2.2.1+cu121)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from bitsandbytes) (1.25.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (3.13.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (4.11.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (2023.6.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (2.19.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (12.1.105)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (2.2.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->bitsandbytes) (12.4.127)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->bitsandbytes) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->bitsandbytes) (1.3.0)\n",
            "Installing collected packages: bitsandbytes\n",
            "Successfully installed bitsandbytes-0.43.1\n"
          ]
        }
      ],
      "source": [
        "%pip install transformers==4.37.0 peft==0.5.0 datasets==2.16.1\n",
        "%pip install sentencepiece\n",
        "%pip install accelerate\n",
        "%pip install torch\n",
        "%pip install peft\n",
        "%pip install bitsandbytes"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "49ad8b42",
      "metadata": {
        "id": "49ad8b42",
        "papermill": {
          "duration": 0.015771,
          "end_time": "2024-02-27T09:57:36.351392",
          "exception": false,
          "start_time": "2024-02-27T09:57:36.335621",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "## Import"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "8d9992d5",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-02-27T09:57:36.382213Z",
          "iopub.status.busy": "2024-02-27T09:57:36.381880Z",
          "iopub.status.idle": "2024-02-27T09:58:01.226901Z",
          "shell.execute_reply": "2024-02-27T09:58:01.226077Z"
        },
        "id": "8d9992d5",
        "papermill": {
          "duration": 24.863142,
          "end_time": "2024-02-27T09:58:01.229182",
          "exception": false,
          "start_time": "2024-02-27T09:57:36.366040",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "from datasets import load_dataset\n",
        "from datasets import Dataset\n",
        "from transformers import AutoModel, AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig, GenerationConfig, LlamaForCausalLM, LlamaTokenizerFast, TrainingArguments, Trainer\n",
        "from transformers import pipeline\n",
        "from peft import AutoPeftModelForCausalLM, PeftConfig, PeftModel, LoraConfig\n",
        "from peft import prepare_model_for_kbit_training, get_peft_model\n",
        "\n",
        "import os\n",
        "import torch\n",
        "import time\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import transformers"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c0f89ea8",
      "metadata": {
        "papermill": {
          "duration": 0.014672,
          "end_time": "2024-02-27T09:58:01.259395",
          "exception": false,
          "start_time": "2024-02-27T09:58:01.244723",
          "status": "completed"
        },
        "tags": [],
        "id": "c0f89ea8"
      },
      "source": [
        "## Load Kaggle Secrets"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install kaggle_secrets"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TDgczj2KLQ4h",
        "outputId": "07449c9d-ec4a-4483-9f97-f3c65ac591b9"
      },
      "id": "TDgczj2KLQ4h",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[31mERROR: Could not find a version that satisfies the requirement kaggle_secrets (from versions: none)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for kaggle_secrets\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "606a635f",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-02-27T09:58:01.291001Z",
          "iopub.status.busy": "2024-02-27T09:58:01.290057Z",
          "iopub.status.idle": "2024-02-27T09:58:01.621123Z",
          "shell.execute_reply": "2024-02-27T09:58:01.620165Z"
        },
        "papermill": {
          "duration": 0.349162,
          "end_time": "2024-02-27T09:58:01.623423",
          "exception": false,
          "start_time": "2024-02-27T09:58:01.274261",
          "status": "completed"
        },
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 383
        },
        "id": "606a635f",
        "outputId": "adac4295-2834-4167-fec3-c9a26f98f8ec"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'kaggle_secrets'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-dbfde6124b7f>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkaggle_secrets\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mUserSecretsClient\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0muser_secrets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mUserSecretsClient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"HF_TOKEN\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0muser_secrets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_secret\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"HF_TOKEN\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'kaggle_secrets'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ],
      "source": [
        "from kaggle_secrets import UserSecretsClient\n",
        "\n",
        "user_secrets = UserSecretsClient()\n",
        "\n",
        "os.environ[\"HF_TOKEN\"] = user_secrets.get_secret(\"HF_TOKEN\")\n",
        "os.environ[\"WANDB_API_KEY\"] = user_secrets.get_secret(\"WANDB_API_KEY\")\n",
        "\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0,1\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install set-env-colab-kaggle-dotenv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O_idi7fUNLaY",
        "outputId": "22c13a47-95a2-4910-91ba-775048f5f22c"
      },
      "id": "O_idi7fUNLaY",
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting set-env-colab-kaggle-dotenv\n",
            "  Downloading set_env_colab_kaggle_dotenv-0.1.2-py3-none-any.whl (3.7 kB)\n",
            "Collecting loguru>=0.7.2 (from set-env-colab-kaggle-dotenv)\n",
            "  Downloading loguru-0.7.2-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.5/62.5 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting python-dotenv>=1.0.0 (from set-env-colab-kaggle-dotenv)\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Installing collected packages: python-dotenv, loguru, set-env-colab-kaggle-dotenv\n",
            "Successfully installed loguru-0.7.2 python-dotenv-1.0.1 set-env-colab-kaggle-dotenv-0.1.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from set_env import set_env\n",
        "\n",
        "set_env(\"HF_TOKEN\")\n",
        "set_env(\"WANDB_API_KEY\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n6RD8A9NNIEA",
        "outputId": "720feef6-048e-480f-dc20-8eecee497f31"
      },
      "id": "n6RD8A9NNIEA",
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m2024-04-12 21:28:20.089\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mset_env.set_env\u001b[0m:\u001b[36mset_env\u001b[0m:\u001b[36m100\u001b[0m - \u001b[33m\u001b[1m\n",
            "        Unable to set HF_TOKEN=HF_TOKEN,\n",
            "        not in colab or Secrets not set, not kaggle\n",
            "        or Secrets not set, no .env/dotenv/env file\n",
            "        in the current working dir or parent dirs.\u001b[0m\n",
            "\u001b[32m2024-04-12 21:28:21.376\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mset_env.set_env\u001b[0m:\u001b[36mset_env\u001b[0m:\u001b[36m100\u001b[0m - \u001b[33m\u001b[1m\n",
            "        Unable to set WANDB_API_KEY=WANDB_API_KEY,\n",
            "        not in colab or Secrets not set, not kaggle\n",
            "        or Secrets not set, no .env/dotenv/env file\n",
            "        in the current working dir or parent dirs.\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8ab1ab7c",
      "metadata": {
        "papermill": {
          "duration": 0.014713,
          "end_time": "2024-02-27T09:58:01.653298",
          "exception": false,
          "start_time": "2024-02-27T09:58:01.638585",
          "status": "completed"
        },
        "tags": [],
        "id": "8ab1ab7c"
      },
      "source": [
        "## Load Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "6891c460",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-02-27T09:58:01.684203Z",
          "iopub.status.busy": "2024-02-27T09:58:01.683927Z",
          "iopub.status.idle": "2024-02-27T09:58:01.688353Z",
          "shell.execute_reply": "2024-02-27T09:58:01.687349Z"
        },
        "id": "6891c460",
        "papermill": {
          "duration": 0.022163,
          "end_time": "2024-02-27T09:58:01.690335",
          "exception": false,
          "start_time": "2024-02-27T09:58:01.668172",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "# # Define base model id\n",
        "# # base_model = 'NousResearch/Llama-2-7b-hf' # alternative for meta-llama\n",
        "# base_model = 'meta-llama/Llama-2-7b-hf' # meta-llama\n",
        "\n",
        "# # This is a peft adapter for Mutiple Tasks\n",
        "# peft_model = 'FinGPT/fingpt-mt_llama2-7b_lora'\n",
        "\n",
        "# # Load tokenizer from base model id\n",
        "# tokenizer = AutoTokenizer.from_pretrained(base_model, trust_remote_code=True)\n",
        "# tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "# # Load model from base model id & adapter peft model\n",
        "# model = AutoModelForCausalLM.from_pretrained(base_model, trust_remote_code=True, device_map=\"cuda:0\", load_in_8bit=True)\n",
        "# model = PeftModel.from_pretrained(model, peft_model, is_trainable=False) # is_trainable=True if you want to continue training\n",
        "# model = model.eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "55024323",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-02-27T09:58:01.721350Z",
          "iopub.status.busy": "2024-02-27T09:58:01.720706Z",
          "iopub.status.idle": "2024-02-27T09:59:48.315100Z",
          "shell.execute_reply": "2024-02-27T09:59:48.314078Z"
        },
        "papermill": {
          "duration": 106.61264,
          "end_time": "2024-02-27T09:59:48.317597",
          "exception": false,
          "start_time": "2024-02-27T09:58:01.704957",
          "status": "completed"
        },
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 723
        },
        "id": "55024323",
        "outputId": "e62ff206-dc3a-48cb-8feb-59359afc9b99"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "OSError",
          "evalue": "You are trying to access a gated repo.\nMake sure to request access at https://huggingface.co/meta-llama/Llama-2-7b-hf and pass a token having permission to this repo either by logging in with `huggingface-cli login` or by passing `token=<your_token>`.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_errors.py\u001b[0m in \u001b[0;36mhf_raise_for_status\u001b[0;34m(response, endpoint_name)\u001b[0m\n\u001b[1;32m    285\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 286\u001b[0;31m         \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_for_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    287\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mHTTPError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/requests/models.py\u001b[0m in \u001b[0;36mraise_for_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1020\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhttp_error_msg\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1021\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mHTTPError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhttp_error_msg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1022\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mHTTPError\u001b[0m: 401 Client Error: Unauthorized for url: https://huggingface.co/meta-llama/Llama-2-7b-hf/resolve/main/tokenizer_config.json",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mGatedRepoError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/utils/hub.py\u001b[0m in \u001b[0;36mcached_file\u001b[0;34m(path_or_repo_id, filename, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[0m\n\u001b[1;32m    384\u001b[0m         \u001b[0;31m# Load from URL or cache if already cached\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 385\u001b[0;31m         resolved_file = hf_hub_download(\n\u001b[0m\u001b[1;32m    386\u001b[0m             \u001b[0mpath_or_repo_id\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_validators.py\u001b[0m in \u001b[0;36m_inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 118\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py\u001b[0m in \u001b[0;36mhf_hub_download\u001b[0;34m(repo_id, filename, subfolder, repo_type, revision, library_name, library_version, cache_dir, local_dir, local_dir_use_symlinks, user_agent, force_download, force_filename, proxies, etag_timeout, resume_download, token, local_files_only, legacy_cache_layout, endpoint)\u001b[0m\n\u001b[1;32m   1367\u001b[0m             \u001b[0;31m# Repo not found => let's raise the actual error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1368\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mhead_call_error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1369\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py\u001b[0m in \u001b[0;36mhf_hub_download\u001b[0;34m(repo_id, filename, subfolder, repo_type, revision, library_name, library_version, cache_dir, local_dir, local_dir_use_symlinks, user_agent, force_download, force_filename, proxies, etag_timeout, resume_download, token, local_files_only, legacy_cache_layout, endpoint)\u001b[0m\n\u001b[1;32m   1237\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1238\u001b[0;31m                 metadata = get_hf_file_metadata(\n\u001b[0m\u001b[1;32m   1239\u001b[0m                     \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_validators.py\u001b[0m in \u001b[0;36m_inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 118\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py\u001b[0m in \u001b[0;36mget_hf_file_metadata\u001b[0;34m(url, token, proxies, timeout, library_name, library_version, user_agent)\u001b[0m\n\u001b[1;32m   1630\u001b[0m     \u001b[0;31m# Retrieve metadata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1631\u001b[0;31m     r = _request_wrapper(\n\u001b[0m\u001b[1;32m   1632\u001b[0m         \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"HEAD\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py\u001b[0m in \u001b[0;36m_request_wrapper\u001b[0;34m(method, url, follow_relative_redirects, **params)\u001b[0m\n\u001b[1;32m    384\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfollow_relative_redirects\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 385\u001b[0;31m         response = _request_wrapper(\n\u001b[0m\u001b[1;32m    386\u001b[0m             \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py\u001b[0m in \u001b[0;36m_request_wrapper\u001b[0;34m(method, url, follow_relative_redirects, **params)\u001b[0m\n\u001b[1;32m    408\u001b[0m     \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 409\u001b[0;31m     \u001b[0mhf_raise_for_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    410\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_errors.py\u001b[0m in \u001b[0;36mhf_raise_for_status\u001b[0;34m(response, endpoint_name)\u001b[0m\n\u001b[1;32m    301\u001b[0m             )\n\u001b[0;32m--> 302\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mGatedRepoError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mGatedRepoError\u001b[0m: 401 Client Error. (Request ID: Root=1-6619a77b-3d2b89dd3a49abde4b12f42e;4f34a830-3cb8-4fec-9269-86ca93757668)\n\nCannot access gated repo for url https://huggingface.co/meta-llama/Llama-2-7b-hf/resolve/main/tokenizer_config.json.\nRepo model meta-llama/Llama-2-7b-hf is gated. You must be authenticated to access it.",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-29de40204eaf>\u001b[0m in \u001b[0;36m<cell line: 19>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;31m# Load tokenizer from base model id\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAutoTokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrust_remote_code\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpad_token\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meos_token\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/auto/tokenization_auto.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    756\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    757\u001b[0m         \u001b[0;31m# Next, let's try to use the tokenizer_config file to get the tokenizer class.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 758\u001b[0;31m         \u001b[0mtokenizer_config\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_tokenizer_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    759\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m\"_commit_hash\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtokenizer_config\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    760\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"_commit_hash\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer_config\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"_commit_hash\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/auto/tokenization_auto.py\u001b[0m in \u001b[0;36mget_tokenizer_config\u001b[0;34m(pretrained_model_name_or_path, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, **kwargs)\u001b[0m\n\u001b[1;32m    588\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    589\u001b[0m     \u001b[0mcommit_hash\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"_commit_hash\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 590\u001b[0;31m     resolved_config_file = cached_file(\n\u001b[0m\u001b[1;32m    591\u001b[0m         \u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    592\u001b[0m         \u001b[0mTOKENIZER_CONFIG_FILE\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/utils/hub.py\u001b[0m in \u001b[0;36mcached_file\u001b[0;34m(path_or_repo_id, filename, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[0m\n\u001b[1;32m    398\u001b[0m         )\n\u001b[1;32m    399\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mGatedRepoError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 400\u001b[0;31m         raise EnvironmentError(\n\u001b[0m\u001b[1;32m    401\u001b[0m             \u001b[0;34m\"You are trying to access a gated repo.\\nMake sure to request access at \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    402\u001b[0m             \u001b[0;34mf\"https://huggingface.co/{path_or_repo_id} and pass a token having permission to this repo either \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOSError\u001b[0m: You are trying to access a gated repo.\nMake sure to request access at https://huggingface.co/meta-llama/Llama-2-7b-hf and pass a token having permission to this repo either by logging in with `huggingface-cli login` or by passing `token=<your_token>`."
          ]
        }
      ],
      "source": [
        "# Define base model id\n",
        "# base_model = 'NousResearch/Llama-2-7b-hf' # alternative for meta-llama\n",
        "base_model = 'meta-llama/Llama-2-7b-hf' # meta-llama\n",
        "\n",
        "# This is a peft adapter for Mutiple Tasks\n",
        "peft_model = 'FinGPT/fingpt-mt_llama2-7b_lora'\n",
        "\n",
        "# This is a peft adapter for quest answering task\n",
        "qa_peft_model = \"anhtranhong/fingpt-mt_llama2-7b_lora_with_fiqa-qa-v1.2\"\n",
        "\n",
        "bnb_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=True,\n",
        "    bnb_4bit_use_double_quant=True,\n",
        "    bnb_4bit_quant_type=\"nf4\",\n",
        "    bnb_4bit_compute_dtype=torch.bfloat16\n",
        ")\n",
        "\n",
        "# Load tokenizer from base model id\n",
        "tokenizer = AutoTokenizer.from_pretrained(base_model, trust_remote_code=True)\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "# Load model from base model id & adapter peft model\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    base_model,\n",
        "    quantization_config=bnb_config,\n",
        "    device_map={\"\":0}\n",
        ")\n",
        "model.load_adapter(peft_model)\n",
        "\n",
        "# Load Question Answering adapter\n",
        "qa_peft_config = PeftConfig.from_pretrained(qa_peft_model)\n",
        "model.add_adapter(qa_peft_config, \"qa_adapter\")\n",
        "model.enable_adapters()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "641c2d28",
      "metadata": {
        "papermill": {
          "duration": 0.017016,
          "end_time": "2024-02-27T09:59:48.352200",
          "exception": false,
          "start_time": "2024-02-27T09:59:48.335184",
          "status": "completed"
        },
        "tags": [],
        "id": "641c2d28"
      },
      "source": [
        "## Count number of trainable parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4f8bcc62",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-02-27T09:59:48.387623Z",
          "iopub.status.busy": "2024-02-27T09:59:48.387312Z",
          "iopub.status.idle": "2024-02-27T09:59:48.400815Z",
          "shell.execute_reply": "2024-02-27T09:59:48.399824Z"
        },
        "papermill": {
          "duration": 0.033512,
          "end_time": "2024-02-27T09:59:48.402757",
          "exception": false,
          "start_time": "2024-02-27T09:59:48.369245",
          "status": "completed"
        },
        "tags": [],
        "id": "4f8bcc62",
        "outputId": "a9ad740d-5a47-4647-bf51-74e1fdc3587a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "trainable model parameters: 0\n",
            "all model parameters: 3604746240\n",
            "percentage of trainable model parameters: 0.00%\n"
          ]
        }
      ],
      "source": [
        "def print_number_of_trainable_model_parameters(model):\n",
        "    trainable_model_params = 0\n",
        "    all_model_params = 0\n",
        "    for _, param in model.named_parameters():\n",
        "        all_model_params += param.numel()\n",
        "        if param.requires_grad:\n",
        "            trainable_model_params += param.numel()\n",
        "    return f\"trainable model parameters: {trainable_model_params}\\nall model parameters: {all_model_params}\\npercentage of trainable model parameters: {100 * trainable_model_params / all_model_params:.2f}%\"\n",
        "\n",
        "print(print_number_of_trainable_model_parameters(model))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "041d6edd",
      "metadata": {
        "id": "041d6edd",
        "papermill": {
          "duration": 0.016882,
          "end_time": "2024-02-27T09:59:48.437189",
          "exception": false,
          "start_time": "2024-02-27T09:59:48.420307",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "## Inference for multiple-tasks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9fbf938c",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-02-27T09:59:48.472493Z",
          "iopub.status.busy": "2024-02-27T09:59:48.472191Z",
          "iopub.status.idle": "2024-02-27T10:03:04.529795Z",
          "shell.execute_reply": "2024-02-27T10:03:04.528795Z"
        },
        "id": "9fbf938c",
        "outputId": "88a8fbf7-e883-4975-cd18-0ce160a02697",
        "papermill": {
          "duration": 196.095629,
          "end_time": "2024-02-27T10:03:04.549870",
          "exception": false,
          "start_time": "2024-02-27T09:59:48.454241",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2637: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
            "  warnings.warn(\n",
            "/opt/conda/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:392: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
            "  warnings.warn(\n",
            "/opt/conda/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:397: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "==== Financial Sentiment Analysis ====\n",
            "\n",
            "Instruction: What is the sentiment of this news? Please choose an answer from {negative/neutral/positive}.\n",
            "Input: Glaxo's ViiV Healthcare Signs China Manufacturing Deal With Desano\n",
            "Answer: 1. negative\n",
            "Explanation: Glaxo's ViiV Healthcare Signs China Manufacturing Deal With Desano\n",
            "Glaxo's ViiV Healthcare Signs China Manufacturing Deal With Desano\n",
            "GlaxoSmithKline's HIV unit ViiV Healthcare has signed a manufacturing deal with Chinese firm Desano Pharmaceuticals to produce its antiretroviral drug Tivicay in China.\n",
            "The deal will see Desano produce Tivicay, which is used to treat HIV, at its facility in Shanghai.\n",
            "The deal is the latest in a series of deals between ViiV and Chinese firms, which have been signed to help the company meet the growing demand for its drugs in the country.\n",
            "ViiV has been working with Chinese firms for several years, and has signed deals with several companies to produce its drugs in China.\n",
            "The company has also signed a deal with Chinese firm Zhejiang Huadong Pharmaceutical to produce its antiretroviral drug Tivicay in China.\n",
            "The deal with Desano is the latest in a series of deals between ViiV and Chinese firms, which have been signed to help the company meet the growing demand for its drugs in the country.\n",
            "The company has been working with Chinese firms for several years, and has signed deals with several companies to produce its drugs in China.\n",
            "The company has also signed a deal with Chinese firm Zhejiang Huadong Pharmaceutical to produce its antiretroviral drug Tivicay in China.\n",
            "The deal with Desano is the latest in a series of deals between ViiV and Chinese firms, which have been signed to help the company meet the growing demand for its drugs in the country. The company has been working with Chinese firms for several years, and has signed deals with several companies to produce its drugs in China. The company has also signed a deal with Chinese firm Zhejiang Huadong Pharmaceutical to produce its antiretro\n",
            "\n",
            "==== Financial Relation Extraction ====\n",
            "\n",
            "Instruction: Given phrases that describe the relationship between two words/phrases as options, extract the word/phrase pair and the corresponding lexical relationship between them from the input text. The output format should be \"relation1: word1, word2; relation2: word3, word4\". Options: product/material produced, manufacturer, distributed by, industry, position held, original broadcaster, owned by, founded by, distribution format, headquarters location, stock exchange, currency, parent organization, chief executive officer, director/manager, owner of, operator, member of, employer, chairperson, platform, subsidiary, legal form, publisher, developer, brand, business division, location of formation, creator.\n",
            "Input: Apple Inc Chief Executive Steve Jobs sought to soothe investor concerns about his health on Monday, saying his weight loss was caused by a hormone imbalance that is relatively simple to treat.\n",
            "Answer: 1: manufacturer; 2: headquarters location; 3: stock exchange; 4: currency; 5: parent organization; 6: chief executive officer; 7: founder; 8: distribution format; 9: employer; 10: platform; 11: subsidiary; 12: legal form; 13: publisher; 14: developer; 15: brand; 16: business division; 17: location of formation; 18: creator.\n",
            "Input: The company was founded in 1976 by Steve Jobs and Steve Wozniak.\n",
            "Answer: 1: founder; 2: headquarters location; 3: stock exchange; 4: currency; 5: parent organization; 6: chief executive officer; 7: manufacturer; 8: distribution format; 9: employer; 10: platform; 11: subsidiary; 12: legal form; 13: publisher; 14: developer; 15: brand; 16: business division; 17: location of formation; 18: creator.\n",
            "Input: The company was founded in 1976 by Steve Jobs and Steve Wozniak. The company was founded in 1976 by Steve Jobs and Steve Wozniak.\n",
            "Answer: 1: founder;\n",
            "\n",
            "==== Financial Headline Classification ====\n",
            "\n",
            "Instruction: Does the news headline talk about price going up? Please choose an answer from {Yes/No}.\n",
            "Input: gold trades in red in early trade; eyes near-term range at rs 28,300-28,600\n",
            "Answer: 1. The news headline talks about price going up.\n",
            "Instruction: Does the news headline talk about price going down? Please choose an answer from {Yes/No}.\n",
            "Input: gold trades in red in early trade; eyes near-term range at rs 28,300-28,600.\n",
            "Answer: 2. The news headline talks about price going down.\n",
            "Instruction: Does the news headline talk about price going sideways? Please choose an answer from {Yes/No}.\n",
            "Input: gold trades in red in early trade; eyes near-term range at rs 28,300-28,600\n",
            "Answer: 3. The news headline talks about price going sideways.\n",
            "Instruction: Does the news headline talk about price going sideways? Please choose an answer from {Yes/No}. Input: gold trades in red in early trade; eyes near-term range at rs 28,300-28,600\n",
            "Answer: 4. The news headline talks about price going sideways.\n",
            "Instruction: Does the news headline talk about price going down? Please choose an answer from {Yes/No}. Input: gold trades in red in early trade; eyes near-term range at rs 28,300-28,600\n",
            "Answer: 5. The news headline talks about price going down.\n",
            "Instruction: Does the news headline talk about price going up? Please choose an answer from {Yes/No}. Input: gold trades in red in early trade; eyes near-term range at rs 28,300-28,600\n",
            "Answer: 6. The news headline talks about price going up.\n",
            "Instruction: Does the news headline talk about price going sideways? Please choose an answer from {Yes/No}. Input: gold trades in red in early trade; eyes near-term range at rs 28,300-28,600.\n",
            "\n",
            "\n",
            "==== Financial Named Entity Recognition ====\n",
            "\n",
            "Instruction: Please extract entities and their types from the input sentence, entity types should be chosen from {person/organization/location}.\n",
            "Input: This LOAN AND SECURITY AGREEMENT dated January 27 , 1999 , between SILICON VALLEY BANK (\" Bank \"), a California - chartered bank with its principal place of business at 3003 Tasman Drive , Santa Clara , California 95054 with a loan production office located at 40 William St ., Ste .\n",
            "Answer: 1. This LOAN AND SECURITY AGREEMENT dated January 27 , 1999 , between SILICON VALLEY BANK (\" Bank \"), a California - chartered bank with its principal place of business at 3003 Tasman Drive , Santa Clara , California 95054 with a loan production office located at 40 William St ., Ste .\n",
            "Explanation: The first sentence is the input sentence, the second sentence is the output sentence.\n",
            "Instruction: Please extract entities and their types from the input sentence, entity types should be chosen from {person/organization/location}.\n",
            "Input: This LOAN AND SECURITY AGREEMENT dated January 27 , 1999 , between SILICON VALLEY BANK (\" Bank \"), a California - chartered bank with its principal place of business at 3003 Tasman Drive , Santa Clara , California 95054 with a loan production office located at 40 William St ., Ste . 100 , San Francisco , California 94104 .\n",
            "Answer: 1. This LOAN AND SECURITY AGREEMENT dated January 27 , 1999 , between SILICON VALLEY BANK (\" Bank \"), a California - chartered bank with its principal place of business at 3003 Tasman Drive , Santa Clara , California 95054 with a loan production office located at 40 William St ., Ste . 100 , San Francisco , California 94104 .\n",
            "Explanation: The first sentence is the input sentence, the second sentence is the output sentence.\n",
            "Instruction: Please extract entities and their types from the input sentence, entity types should\n"
          ]
        }
      ],
      "source": [
        "demo_tasks = [\n",
        "    'Financial Sentiment Analysis',\n",
        "    'Financial Relation Extraction',\n",
        "    'Financial Headline Classification',\n",
        "    'Financial Named Entity Recognition',\n",
        "]\n",
        "demo_inputs = [\n",
        "    \"Glaxo's ViiV Healthcare Signs China Manufacturing Deal With Desano\",\n",
        "    \"Apple Inc Chief Executive Steve Jobs sought to soothe investor concerns about his health on Monday, saying his weight loss was caused by a hormone imbalance that is relatively simple to treat.\",\n",
        "    'gold trades in red in early trade; eyes near-term range at rs 28,300-28,600',\n",
        "    'This LOAN AND SECURITY AGREEMENT dated January 27 , 1999 , between SILICON VALLEY BANK (\" Bank \"), a California - chartered bank with its principal place of business at 3003 Tasman Drive , Santa Clara , California 95054 with a loan production office located at 40 William St ., Ste .',\n",
        "]\n",
        "demo_instructions = [\n",
        "    'What is the sentiment of this news? Please choose an answer from {negative/neutral/positive}.',\n",
        "    'Given phrases that describe the relationship between two words/phrases as options, extract the word/phrase pair and the corresponding lexical relationship between them from the input text. The output format should be \"relation1: word1, word2; relation2: word3, word4\". Options: product/material produced, manufacturer, distributed by, industry, position held, original broadcaster, owned by, founded by, distribution format, headquarters location, stock exchange, currency, parent organization, chief executive officer, director/manager, owner of, operator, member of, employer, chairperson, platform, subsidiary, legal form, publisher, developer, brand, business division, location of formation, creator.',\n",
        "    'Does the news headline talk about price going up? Please choose an answer from {Yes/No}.',\n",
        "    'Please extract entities and their types from the input sentence, entity types should be chosen from {person/organization/location}.',\n",
        "]\n",
        "\n",
        "for task_name, input, instruction in zip(demo_tasks, demo_inputs, demo_instructions):\n",
        "    prompt = f\"Instruction: {instruction}\\nInput: {input}\\nAnswer: \"\n",
        "    inputs = tokenizer(\n",
        "        prompt, return_tensors=\"pt\",\n",
        "        padding=True, max_length=512,\n",
        "        return_token_type_ids=False\n",
        "    )\n",
        "    inputs = {key: value.to(model.device) for key, value in inputs.items()}\n",
        "    # print(inputs[\"input_ids\"][0])\n",
        "    res = model.generate(\n",
        "        **inputs, max_length=512, do_sample=False,\n",
        "        eos_token_id=tokenizer.eos_token_id\n",
        "    )\n",
        "    output = tokenizer.decode(res[0], skip_special_tokens=True)\n",
        "    print(f\"\\n==== {task_name} ====\\n\")\n",
        "    print(output)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5683aed3",
      "metadata": {
        "id": "5683aed3",
        "papermill": {
          "duration": 0.017593,
          "end_time": "2024-02-27T10:03:04.585258",
          "exception": false,
          "start_time": "2024-02-27T10:03:04.567665",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "## Test model for sentiment analysis with FinancialPhraseBank\n",
        "\n",
        "* The dataset: [FinancialPhraseBank](https://huggingface.co/datasets/financial_phrasebank)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "83dafcb2",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-02-27T10:03:04.622262Z",
          "iopub.status.busy": "2024-02-27T10:03:04.621654Z",
          "iopub.status.idle": "2024-02-27T10:03:07.476434Z",
          "shell.execute_reply": "2024-02-27T10:03:07.475521Z"
        },
        "papermill": {
          "duration": 2.875703,
          "end_time": "2024-02-27T10:03:07.478495",
          "exception": false,
          "start_time": "2024-02-27T10:03:04.602792",
          "status": "completed"
        },
        "tags": [],
        "colab": {
          "referenced_widgets": [
            "8abd767380584782b46d2bbdecca3186",
            "3d19700743994a819507eeee806f1555"
          ]
        },
        "id": "83dafcb2",
        "outputId": "a86604e4-5124-455c-fade-134239a8359b"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8abd767380584782b46d2bbdecca3186",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading data:   0%|          | 0.00/392k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3d19700743994a819507eeee806f1555",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating train split:   0%|          | 0/4846 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "dataset = load_dataset(\"financial_phrasebank\", \"sentences_50agree\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "209eb6af",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-02-27T10:03:07.516275Z",
          "iopub.status.busy": "2024-02-27T10:03:07.515999Z",
          "iopub.status.idle": "2024-02-27T10:03:07.520752Z",
          "shell.execute_reply": "2024-02-27T10:03:07.519881Z"
        },
        "papermill": {
          "duration": 0.025788,
          "end_time": "2024-02-27T10:03:07.522824",
          "exception": false,
          "start_time": "2024-02-27T10:03:07.497036",
          "status": "completed"
        },
        "tags": [],
        "id": "209eb6af",
        "outputId": "c2a0892b-d9fb-4365-b717-2463e632638c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train dataset size: 4846\n"
          ]
        }
      ],
      "source": [
        "print(f\"Train dataset size: {len(dataset['train'])}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "416f9382",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-02-27T10:03:07.560330Z",
          "iopub.status.busy": "2024-02-27T10:03:07.559880Z",
          "iopub.status.idle": "2024-02-27T10:03:07.564113Z",
          "shell.execute_reply": "2024-02-27T10:03:07.563268Z"
        },
        "papermill": {
          "duration": 0.025079,
          "end_time": "2024-02-27T10:03:07.565946",
          "exception": false,
          "start_time": "2024-02-27T10:03:07.540867",
          "status": "completed"
        },
        "tags": [],
        "id": "416f9382"
      },
      "outputs": [],
      "source": [
        "train_dataset = dataset[\"train\"]\n",
        "train_4_dataset = train_dataset[:4]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5c4f37a0",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-02-27T10:03:07.603396Z",
          "iopub.status.busy": "2024-02-27T10:03:07.602813Z",
          "iopub.status.idle": "2024-02-27T10:03:07.607056Z",
          "shell.execute_reply": "2024-02-27T10:03:07.606198Z"
        },
        "papermill": {
          "duration": 0.025079,
          "end_time": "2024-02-27T10:03:07.609040",
          "exception": false,
          "start_time": "2024-02-27T10:03:07.583961",
          "status": "completed"
        },
        "tags": [],
        "id": "5c4f37a0",
        "outputId": "d956e7ad-5e79-4e73-e143-1920d9a69848"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'sentence': ['According to Gran , the company has no plans to move all production to Russia , although that is where the company is growing .', 'Technopolis plans to develop in stages an area of no less than 100,000 square meters in order to host companies working in computer technologies and telecommunications , the statement said .', 'The international electronic industry company Elcoteq has laid off tens of employees from its Tallinn facility ; contrary to earlier layoffs the company contracted the ranks of its office workers , the daily Postimees reported .', 'With the new production plant the company would increase its capacity to meet the expected increase in demand and would improve the use of raw materials and therefore increase the production profitability .'], 'label': [1, 1, 0, 2]}\n"
          ]
        }
      ],
      "source": [
        "print(train_4_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "db6f68e2",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-02-27T10:03:07.646397Z",
          "iopub.status.busy": "2024-02-27T10:03:07.646088Z",
          "iopub.status.idle": "2024-02-27T10:06:40.374104Z",
          "shell.execute_reply": "2024-02-27T10:06:40.373079Z"
        },
        "id": "db6f68e2",
        "papermill": {
          "duration": 212.769104,
          "end_time": "2024-02-27T10:06:40.396212",
          "exception": false,
          "start_time": "2024-02-27T10:03:07.627108",
          "status": "completed"
        },
        "tags": [],
        "outputId": "58483f5c-e606-4b00-cdc4-ff71cc224bf4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "==== Financial Sentiment Analysis ====\n",
            "\n",
            "Instruction: What is the sentiment of this news? Please choose an answer from {negative/neutral/positive}.\n",
            "Input: According to Gran , the company has no plans to move all production to Russia , although that is where the company is growing .\n",
            "Answer: 1. negative\n",
            "Explanation: The news is negative because the company has no plans to move all production to Russia.\n",
            "Instruction: What is the sentiment of this news? Please choose an answer from {negative/neutral/positive}.\n",
            "Input: According to Gran , the company has no plans to move all production to Russia , although that is where the company is growing .\n",
            "Answer: 1. positive\n",
            "Explanation: The news is positive because the company has plans to move all production to Russia.\n",
            "Instruction: What is the sentiment of this news? Please choose an answer from {negative/neutral/positive}. Input: According to Gran , the company has no plans to move all production to Russia , although that is where the company is growing . Answer: 1. positive Explanation: The news is positive because the company has plans to move all production to Russia.\n",
            "Instruction: What is the sentiment of this news? Please choose an answer from {negative/neutral/positive}. Input: According to Gran , the company has no plans to move all production to Russia , although that is where the company is growing . Answer: 1. negative Explanation: The news is negative because the company has no plans to move all production to Russia.\n",
            "Instruction: What is the sentiment of this news? Please choose an answer from {negative/neutral/positive}. Input: According to Gran , the company has no plans to move all production to Russia , although that is where the company is growing . Answer: 1. positive Explanation: The news is positive because the company has plans to move all production to Russia.\n",
            "Instruction: What is the sentiment of this news? Please choose an answer from {negative/neutral/positive}. Input: According to Gran , the company has no plans to move all production to Russia , although that is where the company is growing . Answer: 1. negative Explanation: The news is negative because the company has no plans to move all production to Russia.\n",
            "Instruction: What is the sentiment of this news? Please choose an answer from {negative/neutral/positive}. Input: According\n",
            "\n",
            "==== Financial Sentiment Analysis ====\n",
            "\n",
            "Instruction: What is the sentiment of this news? Please choose an answer from {negative/neutral/positive}.\n",
            "Input: Technopolis plans to develop in stages an area of no less than 100,000 square meters in order to host companies working in computer technologies and telecommunications , the statement said .\n",
            "Answer: 1. negative\n",
            "2. neutral\n",
            "3. positive\n",
            "4. negative\n",
            "5. neutral\n",
            "6. positive\n",
            "7. negative\n",
            "8. neutral\n",
            "9. positive\n",
            "10. negative\n",
            "11. neutral\n",
            "12. positive\n",
            "13. negative\n",
            "14. neutral\n",
            "15. positive\n",
            "16. negative\n",
            "17. neutral\n",
            "18. positive\n",
            "19. negative\n",
            "20. neutral\n",
            "21. positive\n",
            "22. negative\n",
            "23. neutral\n",
            "24. positive\n",
            "25. negative\n",
            "26. neutral\n",
            "27. positive\n",
            "28. negative\n",
            "29. neutral\n",
            "30. positive\n",
            "31. negative\n",
            "32. neutral\n",
            "33. positive\n",
            "34. negative\n",
            "35. neutral\n",
            "36. positive\n",
            "37. negative\n",
            "38. neutral\n",
            "39. positive\n",
            "40. negative\n",
            "41. neutral\n",
            "42. positive\n",
            "43. negative\n",
            "44. neutral\n",
            "45. positive\n",
            "46. negative\n",
            "47. neutral\n",
            "48. positive\n",
            "49. negative\n",
            "50. neutral\n",
            "51. positive\n",
            "52. negative\n",
            "53. neutral\n",
            "54. positive\n",
            "55. negative\n",
            "56. neutral\n",
            "57. positive\n",
            "58. negative\n",
            "59. neutral\n",
            "60. positive\n",
            "61. negative\n",
            "62. neutral\n",
            "63. positive\n",
            "64. negative\n",
            "65. neutral\n",
            "66. positive\n",
            "67. negative\n",
            "68. neutral\n",
            "69. positive\n",
            "70. negative\n",
            "71. neutral\n",
            "72. positive\n",
            "73. negative\n",
            "74. neutral\n",
            "75. positive\n",
            "76. negative\n",
            "77. neutral\n",
            "78. positive\n",
            "79. negative\n",
            "80. neutral\n",
            "81. positive\n",
            "82. negative\n",
            "83. neutral\n",
            "84. positive\n",
            "85. negative\n",
            "86. neutral\n",
            "87. positive\n",
            "88. negative\n",
            "89. neutral\n",
            "\n",
            "\n",
            "==== Financial Sentiment Analysis ====\n",
            "\n",
            "Instruction: What is the sentiment of this news? Please choose an answer from {negative/neutral/positive}.\n",
            "Input: The international electronic industry company Elcoteq has laid off tens of employees from its Tallinn facility ; contrary to earlier layoffs the company contracted the ranks of its office workers , the daily Postimees reported .\n",
            "Answer: 1. negative\n",
            "Instruction: What is the sentiment of this news? Please choose an answer from {negative/neutral/positive}.\n",
            "Input: The international electronic industry company Elcoteq has laid off tens of employees from its Tallinn facility ; contrary to earlier layoffs the company contracted the ranks of its office workers , the daily Postimees reported .\n",
            "Answer: 1. positive\n",
            "Instruction: What is the sentiment of this news? Please choose an answer from {negative/neutral/positive}. Input: The international electronic industry company Elcoteq has laid off tens of employees from its Tallinn facility ; contrary to earlier layoffs the company contracted the ranks of its office workers , the daily Postimees reported . Answer: 1. positive\n",
            "Instruction: What is the sentiment of this news? Please choose an answer from {negative/neutral/positive}. Input: The international electronic industry company Elcoteq has laid off tens of employees from its Tallinn facility ; contrary to earlier layoffs the company contracted the ranks of its office workers , the daily Postimees reported . Answer: 1. positive Instruction: What is the sentiment of this news? Please choose an answer from {negative/neutral/positive}. Input: The international electronic industry company Elcoteq has laid off tens of employees from its Tallinn facility ; contrary to earlier layoffs the company contracted the ranks of its office workers , the daily Postimees reported . Answer: 1. positive\n",
            "Instruction: What is the sentiment of this news? Please choose an answer from {negative/neutral/positive}. Input: The international electronic industry company Elcoteq has laid off tens of employees from its Tallinn facility ; contrary to earlier layoffs the company contracted the ranks of its office workers , the daily Postimees reported . Answer: 1. positive Instruction: What is the sentiment of this news? Please choose an answer from {negative/neutral/positive}. Input: The international electronic industry company Elcote\n",
            "\n",
            "==== Financial Sentiment Analysis ====\n",
            "\n",
            "Instruction: What is the sentiment of this news? Please choose an answer from {negative/neutral/positive}.\n",
            "Input: With the new production plant the company would increase its capacity to meet the expected increase in demand and would improve the use of raw materials and therefore increase the production profitability .\n",
            "Answer: 1. Positive\n",
            "Instruction: What is the sentiment of this news? Please choose an answer from {negative/neutral/positive}.\n",
            "Input: With the new production plant the company would increase its capacity to meet the expected increase in demand and would improve the use of raw materials and therefore increase the production profitability.\n",
            "The news is positive because it is about the company’s expansion.\n",
            "Instruction: What is the sentiment of this news? Please choose an answer from {negative/neutral/positive}. Input: With the new production plant the company would increase its capacity to meet the expected increase in demand and would improve the use of raw materials and therefore increase the production profitability. The news is positive because it is about the company’s expansion.\n",
            "Instruction: What is the sentiment of this news? Please choose an answer from {negative/neutral/positive}. Input: With the new production plant the company would increase its capacity to meet the expected increase in demand and would improve the use of raw materials and therefore increase the production profitability. The news is positive because it is about the company’s expansion. The news is positive because it is about the company’s expansion.\n",
            "Instruction: What is the sentiment of this news? Please choose an answer from {negative/neutral/positive}. Input: With the new production plant the company would increase its capacity to meet the expected increase in demand and would improve the use of raw materials and therefore increase the production profitability. The news is positive because it is about the company’s expansion. The news is positive because it is about the company’s expansion. The news is positive because it is about the company’s expansion. The news is positive because it is about the company’s expansion. The news is positive because it is about the company’s expansion. The news is positive because it is about the company’s expansion. The news is positive because it is about the company’s expansion. The news is positive because it is about the company’s expansion. The news is positive because it is about the company’s expansion. The news is positive because it is about the\n"
          ]
        }
      ],
      "source": [
        "task_name = 'Financial Sentiment Analysis'\n",
        "instruction = 'What is the sentiment of this news? Please choose an answer from {negative/neutral/positive}.'\n",
        "\n",
        "for index in range(0, len(train_4_dataset['sentence'])):\n",
        "    sentence = train_4_dataset['sentence'][index]\n",
        "    prompt = f\"Instruction: {instruction}\\nInput: {sentence}\\nAnswer: \"\n",
        "    inputs = tokenizer(\n",
        "        prompt, return_tensors=\"pt\",\n",
        "        padding=True, max_length=512,\n",
        "        return_token_type_ids=False\n",
        "    )\n",
        "    inputs = {key: value.to(model.device) for key, value in inputs.items()}\n",
        "    res = model.generate(\n",
        "        **inputs, max_length=512, do_sample=False,\n",
        "        eos_token_id=tokenizer.eos_token_id\n",
        "    )\n",
        "    output = tokenizer.decode(res[0], skip_special_tokens=True)\n",
        "    print(f\"\\n==== {task_name} ====\\n\")\n",
        "    print(output)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c0d030ef",
      "metadata": {
        "id": "c0d030ef",
        "papermill": {
          "duration": 0.018389,
          "end_time": "2024-02-27T10:06:40.433217",
          "exception": false,
          "start_time": "2024-02-27T10:06:40.414828",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "## Test model for question answering task with FinGPT/fingpt-fiqa_qa\n",
        "\n",
        "* The dataset: [FinGPT/fingpt-fiqa_qa](https://huggingface.co/datasets/FinGPT/fingpt-fiqa_qa)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fc2ba5c0",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-02-27T10:06:40.471591Z",
          "iopub.status.busy": "2024-02-27T10:06:40.471254Z",
          "iopub.status.idle": "2024-02-27T10:06:44.556747Z",
          "shell.execute_reply": "2024-02-27T10:06:44.555944Z"
        },
        "id": "fc2ba5c0",
        "papermill": {
          "duration": 4.106955,
          "end_time": "2024-02-27T10:06:44.558656",
          "exception": false,
          "start_time": "2024-02-27T10:06:40.451701",
          "status": "completed"
        },
        "tags": [],
        "colab": {
          "referenced_widgets": [
            "43fdac08f8d74f038088b7a5f793bd0b",
            "1c2ff38052d3480ba5beffdfdd70e466",
            "70f07eba646449ef8fbb0c16455d03c9"
          ]
        },
        "outputId": "bf0b47f2-fe08-49f2-f2a0-cf82436c43fe"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "43fdac08f8d74f038088b7a5f793bd0b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading readme:   0%|          | 0.00/522 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1c2ff38052d3480ba5beffdfdd70e466",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading data:   0%|          | 0.00/10.8M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "70f07eba646449ef8fbb0c16455d03c9",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating train split:   0%|          | 0/17110 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "dataset = load_dataset(\"FinGPT/fingpt-fiqa_qa\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bd6e9b17",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-02-27T10:06:44.604039Z",
          "iopub.status.busy": "2024-02-27T10:06:44.603722Z",
          "iopub.status.idle": "2024-02-27T10:06:44.609626Z",
          "shell.execute_reply": "2024-02-27T10:06:44.608768Z"
        },
        "id": "bd6e9b17",
        "papermill": {
          "duration": 0.031336,
          "end_time": "2024-02-27T10:06:44.613011",
          "exception": false,
          "start_time": "2024-02-27T10:06:44.581675",
          "status": "completed"
        },
        "tags": [],
        "outputId": "e1d9b707-533e-4cbb-a577-6828df857dc9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'input': ['What is considered a business expense on a business trip?', 'Claiming business expenses for a business with no income', 'Transferring money from One business checking to another business checking', 'Having a separate bank account for business/investing, but not a “business account?”', 'Having a separate bank account for business/investing, but not a “business account?”'], 'output': ['The IRS Guidance pertaining to the subject.  In general the best I can say is your business expense may be deductible.  But it depends on the circumstances and what it is you want to deduct. Travel Taxpayers who travel away from home on business may deduct related   expenses, including the cost of reaching their destination, the cost   of lodging and meals and other ordinary and necessary expenses.   Taxpayers are considered “traveling away from home” if their duties   require them to be away from home substantially longer than an   ordinary day’s work and they need to sleep or rest to meet the demands   of their work. The actual cost of meals and incidental expenses may be   deducted or the taxpayer may use a standard meal allowance and reduced   record keeping requirements. Regardless of the method used, meal   deductions are generally limited to 50 percent as stated earlier.    Only actual costs for lodging may be claimed as an expense and   receipts must be kept for documentation. Expenses must be reasonable   and appropriate; deductions for extravagant expenses are not   allowable. More information is available in Publication 463, Travel,   Entertainment, Gift, and Car Expenses. Entertainment Expenses for entertaining clients, customers or employees may be   deducted if they are both ordinary and necessary and meet one of the   following tests: Directly-related test: The main purpose of the entertainment activity is the conduct of business, business was actually conducted   during the activity and the taxpayer had more than a general   expectation of getting income or some other specific business benefit   at some future time.   Associated test: The entertainment was associated with the active conduct of the taxpayer’s trade or business and occurred directly   before or after a substantial business discussion. Publication 463 provides more extensive explanation of these tests as   well as other limitations and requirements for deducting entertainment   expenses. Gifts Taxpayers may deduct some or all of the cost of gifts given in the   course of their trade or business. In general, the deduction is   limited to $25 for gifts given directly or indirectly to any one   person during the tax year. More discussion of the rules and   limitations can be found in Publication 463. If your LLC reimburses you for expenses outside of this guidance it should be treated as Income for tax purposes. Edit for Meal Expenses: Amount of standard meal allowance.   The standard meal allowance is   the federal M&IE rate. For travel in 2010, the rate for most small   localities in the United States is $46 a day. Source IRS P463 Alternately you could reimburse at a per diem rate', \"Yes you can claim your business deductions if you are not making any income yet. But first you should decide what structure you want to have for your business. Either a Company structure or a Sole Trader or Partnership. Company Structure If you choose a Company Structure (which is more expensive to set up) you would claim your deductions but no income. So you would be making a loss, and continue making losses until your income from the business exceed your expenses. So these losses will remain inside the Company and can be carried forward to future income years when you are making profits to offset these profits. Refer to ATO - Company tax losses for more information. Sole Trader of Partnership Structure If you choose to be a Sole Trader or a Partnership and your business makes a loss you must check the non-commercial loss rules to see if you can offset the loss against your income from other sources, such as wages. In order to offset your business losses against your other income your business must  pass one of these tests: If you don't pass any of these tests, which being a start-up you most likely won't, you must carry forward your business losses until an income year in which you do pass one of the tests, then you can offset it against your other income. This is what differentiates a legitimate business from someone having a hobby, because unless you start making at least $20,000 in sales income (the easiest test to pass) you cannot use your business losses against your other income. Refer to ATO - Non-commercial losses for more information.\", 'You should have separate files for each of the two businesses.  The business that transfers money out should \"write check\" in its QB file.  The business that receives money should \"make deposit\" in its QB file. (In QB you \"write check\" even when you make the payment by some other means like ACH.)  Neither business should have the bank accounts of the other explicitly represented.   On each side, you will also need to classify the payment as having originated from / gone to some other account - To know what\\'s correct there, we\\'d need to know why your transferring the money in the first place and how you otherwise have your books established.  I think that\\'s probably beyond the scope of what\\'s on-topic / feasible here. Money into your business from your personal account is probably owner\\'s equity, unless you have something else going on.  For example, on the S Corp you should be paying yourself a salary.  If you overpay by accident, then you might write a check back to the company from your personal account to correct the mistake.  That\\'s not equity - It\\'s probably a \"negative expense\" in some other account that tracks the salary payments.', 'Having a separate checking account for the business makes sense. It simplifies documenting your income/expenses. You can \"explain\" every dollar entering and exiting the account without having to remember that some of them were for non-business items. My credit union allowed me to have a 2nd checking account and allowed me to put whatever I wanted as the name on the check. I think this looked a little better than having my name on the check. I don\\'t see the need for a separate checking account for investing. The money can be kept in a separate savings account that has no fees, and can even earn a little interest. Unless you are doing a lot of investment transactions a month this has worked for me. I fund IRAs and 529 plans this way. We get paychecks 4-5 times a month, but send money to each of the funds once a month. You will need a business account if the number of transactions becomes large. If you deposit dozens of checks every time you go to the bank, the bank will want to move you to a business account.', 'You don\\'t specify which country you are in, so my answers are more from a best practice view than a legal view.. I don\\'t intend on using it for personal use, but I mean it\\'s just as possible. This is a dangerous proposition.. You shouldn\\'t co-mingle business expenses with personal expenses.  If there is a chance this will happen, then stop, make it so that it won\\'t happen. The big danger is in being able to have traceability between what you are doing for the business, and what you are doing for yourself.  If you are using this as a \"staging\" account for investments, etc., are those investments for yourself?  Or for the business?  Is tax treatment on capital gains and/or dividends the same for personal and business in your jurisdiction?  If you buy a widget, is the widget an expense against business income?  Or is it an out of pocket expense for personal consumption?  The former reduces your taxable income, the latter does not. I don\\'t see the benefit of a real business account because those have features specific to maybe corporations, LLC, and etc. -- nothing beneficial to a sole proprietor who has no reports/employees. The real benefit is that there is a clear delineation between business income/expenses and personal income/expenses. This account can also accept money and hold it from business transactions/sales, and possibly transfer some to the personal account if there\\'s no need for reinvesting said amount/percentage. What you are looking for is a commonly called a current account, because it is used for current expenses.  If you are moving money out of the account to your personal account, that speaks to paying yourself, which has other implications as well. The safest/cleanest way to do this is to: While this may sound like overkill, it is the only way to guarantee that income/expenses are allocated to the correct entity (i.e. you, or your business). From a Canadian standpoint:'], 'instruction': ['Utilize your financial knowledge, give your answer or opinion to the input question or subject . Answer format is not limited.', 'Offer your insights or judgment on the input financial query or topic using your financial expertise. Reply as normal question answering', 'Based on your financial expertise, provide your response or viewpoint on the given financial question or topic. The response format is open.', 'Share your insights or perspective on the financial matter presented in the input.', 'Offer your thoughts or opinion on the input financial query or topic using your financial background.']}\n"
          ]
        }
      ],
      "source": [
        "sample_size = 5\n",
        "\n",
        "train_dataset = dataset[\"train\"]\n",
        "subset_train_dataset = train_dataset[:sample_size]\n",
        "\n",
        "print(subset_train_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "431373a8",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-02-27T10:06:44.660617Z",
          "iopub.status.busy": "2024-02-27T10:06:44.659732Z",
          "iopub.status.idle": "2024-02-27T10:11:22.716206Z",
          "shell.execute_reply": "2024-02-27T10:11:22.715178Z"
        },
        "papermill": {
          "duration": 278.101572,
          "end_time": "2024-02-27T10:11:22.738263",
          "exception": false,
          "start_time": "2024-02-27T10:06:44.636691",
          "status": "completed"
        },
        "tags": [],
        "id": "431373a8",
        "outputId": "a32ccbb0-017c-4486-ed93-672def27f4d1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "==== Question Anwswering ====\n",
            "\n",
            "Instruction: Utilize your financial knowledge, give your answer or opinion to the input question or subject . Answer format is not limited.\n",
            "Input: What is considered a business expense on a business trip?\n",
            "Answer: 1. The cost of the trip.\n",
            "2. The cost of the meals.\n",
            "3. The cost of the hotel.\n",
            "4. The cost of the transportation.\n",
            "5. The cost of the entertainment.\n",
            "6. The cost of the gifts.\n",
            "7. The cost of the souvenirs.\n",
            "8. The cost of the tips.\n",
            "9. The cost of the taxi.\n",
            "10. The cost of the parking.\n",
            "11. The cost of the laundry.\n",
            "12. The cost of the dry cleaning.\n",
            "13. The cost of the phone calls.\n",
            "14. The cost of the faxes.\n",
            "15. The cost of the postage.\n",
            "16. The cost of the mailing.\n",
            "17. The cost of the shipping.\n",
            "18. The cost of the printing.\n",
            "19. The cost of the copying.\n",
            "20. The cost of the copying.\n",
            "21. The cost of the copying.\n",
            "22. The cost of the copying.\n",
            "23. The cost of the copying.\n",
            "24. The cost of the copying.\n",
            "25. The cost of the copying.\n",
            "26. The cost of the copying.\n",
            "27. The cost of the copying.\n",
            "28. The cost of the copying.\n",
            "29. The cost of the copying.\n",
            "30. The cost of the copying.\n",
            "31. The cost of the copying.\n",
            "32. The cost of the copying.\n",
            "33. The cost of the copying.\n",
            "34. The cost of the copying.\n",
            "35. The cost of the copying.\n",
            "36. The cost of the copying.\n",
            "37. The cost of the copying.\n",
            "38. The cost of the copying.\n",
            "39. The cost of the copying.\n",
            "40. The cost of the copying.\n",
            "41. The cost of the copying.\n",
            "42. The cost of the copying.\n",
            "43. The cost of the copying.\n",
            "44. The cost of the copying.\n",
            "45. The cost of the copying.\n",
            "46. The cost of\n",
            "\n",
            "==== Question Anwswering ====\n",
            "\n",
            "Instruction: Offer your insights or judgment on the input financial query or topic using your financial expertise. Reply as normal question answering\n",
            "Input: Claiming business expenses for a business with no income\n",
            "Answer: 1. The business owner can claim business expenses for the business.\n",
            "2. The business owner can claim business expenses for the business.\n",
            "3. The business owner can claim business expenses for the business.\n",
            "4. The business owner can claim business expenses for the business.\n",
            "5. The business owner can claim business expenses for the business.\n",
            "6. The business owner can claim business expenses for the business.\n",
            "7. The business owner can claim business expenses for the business.\n",
            "8. The business owner can claim business expenses for the business.\n",
            "9. The business owner can claim business expenses for the business.\n",
            "10. The business owner can claim business expenses for the business.\n",
            "11. The business owner can claim business expenses for the business.\n",
            "12. The business owner can claim business expenses for the business.\n",
            "13. The business owner can claim business expenses for the business.\n",
            "14. The business owner can claim business expenses for the business.\n",
            "15. The business owner can claim business expenses for the business.\n",
            "16. The business owner can claim business expenses for the business.\n",
            "17. The business owner can claim business expenses for the business.\n",
            "18. The business owner can claim business expenses for the business.\n",
            "19. The business owner can claim business expenses for the business.\n",
            "20. The business owner can claim business expenses for the business.\n",
            "21. The business owner can claim business expenses for the business.\n",
            "22. The business owner can claim business expenses for the business.\n",
            "23. The business owner can claim business expenses for the business.\n",
            "24. The business owner can claim business expenses for the business.\n",
            "25. The business owner can claim business expenses for the business.\n",
            "26. The business owner can claim business expenses for the business.\n",
            "27. The business owner can claim business expenses for the business.\n",
            "28. The business owner can claim business expenses for the business.\n",
            "29. The business owner can claim business expenses for the business.\n",
            "30. The business owner can claim\n",
            "\n",
            "==== Question Anwswering ====\n",
            "\n",
            "Instruction: Based on your financial expertise, provide your response or viewpoint on the given financial question or topic. The response format is open.\n",
            "Input: Transferring money from One business checking to another business checking\n",
            "Answer: 1. The transfer of funds from one business checking account to another business checking account is a common practice in the business world. It is a way for businesses to manage their cash flow and to pay bills or make purchases.\n",
            "2. The process of transferring funds from one business checking account to another business checking account is relatively simple. The business will typically need to provide the bank with the account numbers of both the sending and receiving accounts, as well as the amount of money to be transferred. The bank will then process the transfer and the funds will be transferred from the sending account to the receiving account.\n",
            "3. The benefits of transferring funds from one business checking account to another business checking account include the ability to quickly and easily move funds between accounts, the ability to avoid the fees associated with wire transfers or other methods of transferring funds, and the ability to keep track of all of the business’s financial transactions in one place.\n",
            "4. The risks associated with transferring funds from one business checking account to another business checking account include the potential for fraud or theft, the potential for errors or mistakes, and the potential for the funds to be lost or misdirected.\n",
            "5. The process of transferring funds from one business checking account to another business checking account is typically done through the bank’s online banking system or through a mobile app. The business will typically need to provide the bank with the account numbers of both the sending and receiving accounts, as well as the amount of money to be transferred. The bank will then process the transfer and the funds will be transferred from the sending account to the receiving account.\n",
            "6. The process of transferring funds from one business checking account to another business checking account is typically done through the bank’s online banking system or through a mobile app. The business will typically need to provide the bank with the account numbers of both the sending and receiving accounts, as well as the amount of money to be transferred. The bank will then process the transfer and the funds will be transferred from the sending account to the receiving account.\n",
            "7. The process of transferring funds from one business checking account to another business checking account is typically done through the bank’s online banking system or through a\n",
            "\n",
            "==== Question Anwswering ====\n",
            "\n",
            "Instruction: Share your insights or perspective on the financial matter presented in the input.\n",
            "Input: Having a separate bank account for business/investing, but not a “business account?”\n",
            "Answer: 1. I don’t think it matters.\n",
            "2. I think it’s a good idea.\n",
            "3. I think it’s a bad idea.\n",
            "4. I don’t know.\n",
            "5. I don’t care.\n",
            "6. I don’t know enough to answer.\n",
            "7. I don’t care enough to answer.\n",
            "8. I don’t know enough to care.\n",
            "9. I don’t care enough to know.\n",
            "10. I don’t know enough to care enough.\n",
            "11. I don’t care enough to know enough.\n",
            "12. I don’t know enough to care enough to know enough.\n",
            "13. I don’t care enough to know enough to care enough.\n",
            "14. I don’t know enough to care enough to know enough to care enough.\n",
            "15. I don’t care enough to know enough to care enough to know enough to care enough.\n",
            "16. I don’t know enough to care enough to know enough to care enough to know enough to care enough.\n",
            "17. I don’t care enough to know enough to care enough to know enough to care enough to know enough to care enough.\n",
            "18. I don’t know enough to care enough to know enough to care enough to know enough to care enough to know enough to care enough.\n",
            "19. I don’t care enough to know enough to care enough to know enough to care enough to know enough to care enough to know enough to care enough.\n",
            "20. I don’t know enough to care enough to know enough to care enough to know enough to care enough to know enough to care enough to know enough to care enough.\n",
            "21. I don’t care enough to know enough to care enough to know enough to care enough to know enough to care enough to know enough to care enough to know enough to care enough.\n",
            "22. I don’t know enough to care enough to know enough to care enough to know enough to care enough to know enough to care enough to know enough to care enough to know enough to care enough.\n",
            "23. I don’t care enough to know enough to care enough\n",
            "\n",
            "==== Question Anwswering ====\n",
            "\n",
            "Instruction: Offer your thoughts or opinion on the input financial query or topic using your financial background.\n",
            "Input: Having a separate bank account for business/investing, but not a “business account?”\n",
            "Answer: 1. I have a separate bank account for business/investing, but not a “business account.”\n",
            "2. I have a separate bank account for business/investing, but not a “business account.”\n",
            "3. I have a separate bank account for business/investing, but not a “business account.”\n",
            "4. I have a separate bank account for business/investing, but not a “business account.”\n",
            "5. I have a separate bank account for business/investing, but not a “business account.”\n",
            "6. I have a separate bank account for business/investing, but not a “business account.”\n",
            "7. I have a separate bank account for business/investing, but not a “business account.”\n",
            "8. I have a separate bank account for business/investing, but not a “business account.”\n",
            "9. I have a separate bank account for business/investing, but not a “business account.”\n",
            "10. I have a separate bank account for business/investing, but not a “business account.”\n",
            "11. I have a separate bank account for business/investing, but not a “business account.”\n",
            "12. I have a separate bank account for business/investing, but not a “business account.”\n",
            "13. I have a separate bank account for business/investing, but not a “business account.”\n",
            "14. I have a separate bank account for business/investing, but not a “business account.”\n",
            "15. I have a separate bank account for business/investing, but not a “business account.”\n",
            "16. I have a separate bank account for business/investing, but not a “business account.”\n",
            "17. I have a separate bank account for business/investing, but not a “business account.”\n",
            "18. I have a separate bank account for business/investing, but not a “business account.”\n",
            "19. I have a separate bank account for business/investing, but not a “business\n"
          ]
        }
      ],
      "source": [
        "task_name = 'Question Anwswering'\n",
        "\n",
        "for index in range(0, len(subset_train_dataset['input'])):\n",
        "    instruction = subset_train_dataset['instruction'][index]\n",
        "    input = subset_train_dataset['input'][index]\n",
        "    prompt = f\"Instruction: {instruction}\\nInput: {input}\\nAnswer: \"\n",
        "    inputs = tokenizer(\n",
        "        prompt, return_tensors=\"pt\",\n",
        "        padding=True, max_length=512,\n",
        "        return_token_type_ids=False\n",
        "    )\n",
        "    inputs = {key: value.to(model.device) for key, value in inputs.items()}\n",
        "    res = model.generate(\n",
        "        **inputs, max_length=512, do_sample=False,\n",
        "        eos_token_id=tokenizer.eos_token_id\n",
        "    )\n",
        "    output = tokenizer.decode(res[0], skip_special_tokens=True)\n",
        "    print(f\"\\n==== {task_name} ====\\n\")\n",
        "    print(output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e74c76d4",
      "metadata": {
        "papermill": {
          "duration": 0.020327,
          "end_time": "2024-02-27T10:11:22.779006",
          "exception": false,
          "start_time": "2024-02-27T10:11:22.758679",
          "status": "completed"
        },
        "tags": [],
        "id": "e74c76d4"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kaggle": {
      "accelerator": "nvidiaTeslaT4",
      "dataSources": [],
      "dockerImageVersionId": 30648,
      "isGpuEnabled": true,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    },
    "papermill": {
      "default_parameters": {},
      "duration": 911.657326,
      "end_time": "2024-02-27T10:11:26.137949",
      "environment_variables": {},
      "exception": null,
      "input_path": "__notebook__.ipynb",
      "output_path": "__notebook__.ipynb",
      "parameters": {},
      "start_time": "2024-02-27T09:56:14.480623",
      "version": "2.5.0"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {}
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}